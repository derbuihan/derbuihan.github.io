<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>機械学習 | derbuihan blog</title>
<meta name=keywords content><meta name=description content="ExampleSite description"><meta name=author content="derbuihan"><link rel=canonical href=https://derbuihan.github.io/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://derbuihan.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://derbuihan.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://derbuihan.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://derbuihan.github.io/apple-touch-icon.png><link rel=mask-icon href=https://derbuihan.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://derbuihan.github.io/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="機械学習"><meta property="og:description" content="ExampleSite description"><meta property="og:type" content="website"><meta property="og:url" content="https://derbuihan.github.io/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/"><meta property="og:image" content="https://derbuihan.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://derbuihan.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="機械学習"><meta name=twitter:description content="ExampleSite description"></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://derbuihan.github.io/ accesskey=h title="derbuihan blog (Alt + H)"><img src=https://derbuihan.github.io/apple-touch-icon.png alt aria-label=logo height=35>derbuihan blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://derbuihan.github.io/about/ title=About><span>About</span></a></li><li><a href=https://derbuihan.github.io/works/ title=Works><span>Works</span></a></li><li><a href=https://derbuihan.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://derbuihan.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://derbuihan.github.io/tags/>Tags</a></div><h1>機械学習
<a href=/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/index.xml title=RSS aria-label=RSS><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>MNIST画像認識の実験</h2></header><div class=entry-content><p>全結合層のネットワークや CNN を用いて MNIST 画像認識の実験をした。
実験環境 tensorflow v2.4.0 optimizer=‘adam’, loss=‘sparse_categorical_crossentropy’ MNIST のデータの中身 MNIST は 0~9 の手書き文字とそのラベルのデータセットである。 6 万枚の train データと 1 万枚の test データに分かれている。
この記事では、次のように前処理を行った。
import tensorflow as tf (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data() X_train = X_train.astype('float32') / 255 X_test = X_test.astype('float32') / 255 0~255 の値を 255 で割ることで 0~1 の値にすることによって、勾配消失を防ぐことが出来る。
普通に学習 全結合のモデル (その 1) 下記のような全結合が 2 層のモデルを作った。
model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28,)), tf.keras.layers.Dense(512, activation='relu'), tf.keras.layers.Dropout(0.25), tf.keras.layers.Dense(10, activation='softmax') ]) 全パラメータの数は 407,050。...</p></div><footer class=entry-footer><span title='2021-01-03 06:16:50 +0900 JST'>January 3, 2021</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;475 words&nbsp;·&nbsp;derbuihan</footer><a class=entry-link aria-label="post link to MNIST画像認識の実験" href=https://derbuihan.github.io/posts/mnist_experiment/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Tensorflow Datasetsにある英語の巨大なテキストのデータセット</h2></header><div class=entry-content><p>Tensorflow Datasets の中から英語の文章のデータセットをまとめます。
データの一覧の取得 以下のコマンドでtensorflow_datasetsから取得出来るデータセットの一覧がわかります。
>>> import tensorflow_datasets as tfds >>> tfds.list_builders() 英語のデータセット 大量のテキストのデータセット
c4 Web クロールで集めた巨大なデータセット。英語のは約 1TB ある。 英語以外の言語もデータがあり、すべての言語合わせると 26.76TB あるらしい。
librispeech_lm 5GB のデータセット
lm1b 5GB のデータセット
pg19 古い本のデータセット。10GB ぐらい。
reddit_disentanglement reddit のデータセット。
wiki40b wikipedia のデータセット。きれいになってる。
wikipedia wikipedia のデータセット。きれいになってない。
その他データセット その他の使えそうなデータセット
ag_news_subset ニュース記事のタイトルと説明文が、その記事の種類にラベル付けされたデータセット。
math_dataset 数学に関する英語の問題とその答えのデータセット
tiny_shakespeare シェイクスピアの文章</p></div><footer class=entry-footer><span title='2020-12-23 02:42:40 +0900 JST'>December 23, 2020</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;48 words&nbsp;·&nbsp;derbuihan</footer><a class=entry-link aria-label="post link to Tensorflow Datasetsにある英語の巨大なテキストのデータセット" href=https://derbuihan.github.io/posts/tensorflow_datasets_text/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>i7 870にTensorflowの環境構築方法</h2></header><div class=entry-content><p>はじめに 落ちてた i7 870 のパソコンにグラボを 2 枚刺して、機械学習専用サーバーを作りました。 このとき、最新の Tensorflow をインストールしても使えないので苦労しました。 これは i7 870 は Sandy Bridge 以前の CPU なので AVX 命令がないのが原因です。 この記事では i7 870 でも機械学習が出来るように、少し古めの Tensorflow の環境を構築する方法を解説します。
この情報は 2020 年 12 月に出来た方法です。
前提 CUDA 10.2 Nvidia Driver Version: 440.100 Anaconda をインストール tensorflow v1.5.0 のインストール方法 はじめに、仮想環境の作成
$ conda create -n tf1 python==3.7 anaconda $ conda activate tf1 tensorflow-gpu v1.15.0 を指定してインストール
$ conda install -c anaconda tensorflow-gpu==1.15.0 $ conda install -c anaconda keras ついでに、tensorflow-datasets をインストール(conda で入るのはバージョンが古いので pip でインストール)...</p></div><footer class=entry-footer><span title='2020-12-18 12:05:33 +0900 JST'>December 18, 2020</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;174 words&nbsp;·&nbsp;derbuihan</footer><a class=entry-link aria-label="post link to i7 870にTensorflowの環境構築方法" href=https://derbuihan.github.io/posts/tensorflow_i7_870/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>tensorflow-gpuをDockerで動かしたときにIllegal instructionと出たときの対処法</h2></header><div class=entry-content><p>はじめに Docker 19.03 以降から Docker のコンテナから Nvidia GPU を使いやすくなりました。 tensorflow-gpu を Docker で使う場合は、公式のtensorflow/tensorflow:latest-gpu-py3があります。
エラーの内容 このコンテナを Sandy Bridge 以前の CPU で使うと
Illegal instruction (core dumped) というエラーが出ます。 これは AVX という命令が古すぎる CPU にはないために起こるエラーです。
解決方法 解決方法は
tensorflow をコンテナ内でビルドする 古い CPU でも動く tensorflow をどっかから取ってくる。 の二種類があります。
この記事では 2.を使い、Anaconda のリポジトリから取ってきた tensorflow-gpu を用いたDockerfileを書いたので紹介します。
使い方 Dockerfileを使ってください。
動作環境 Ubuntu 18.04 docker 19.03 以降 nvidia-driver-435 遊び方 環境がきちんと整っていれば次で動作すると思います。
$ git clone https://github.com/derbuihan/docker-tensorflow-gpu $ cd docker-tensorflow-gpu $ docker build -t mnist_sample . $ docker run --gpus device=0 -it --rm mnist_sample /bin/bash (base)$ conda activate tf-gpu (tf-gpu)$ wget https://raw....</p></div><footer class=entry-footer><span title='2019-10-03 04:47:58 +0900 JST'>October 3, 2019</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;88 words&nbsp;·&nbsp;derbuihan</footer><a class=entry-link aria-label="post link to tensorflow-gpuをDockerで動かしたときにIllegal instructionと出たときの対処法" href=https://derbuihan.github.io/posts/docker_tensorflow_gpu/></a></article></main><footer class=footer><span>&copy; 2024 <a href=https://derbuihan.github.io/>derbuihan blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>